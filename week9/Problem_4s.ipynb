{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7778f348fa22a203c4a15bba1c7d0c0c",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Week 9 Problem 4\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `YOUR CODE HERE`. Do not write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select *Kernel*, and restart the kernel and run all cells (*Restart & Run all*).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select *File* → *Save and CheckPoint*)\n",
    "\n",
    "5. When you are ready to submit your assignment, go to *Dashboard* → *Assignments* and click the *Submit* button. Your work is not submitted until you click *Submit*.\n",
    "\n",
    "6. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded.\n",
    "\n",
    "## Author: Radhir Kothuri\n",
    "### Primary Reviewer: Kelechi Ikegwu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f85750f7fb93abf0d0482fc9c296d010",
     "grade": false,
     "grade_id": "due_date",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Due Date: 6 PM, March 26, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4d1a8ba6b53111a046ce300e03b17370",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.testing import assert_array_equal\n",
    "from nose.tools import assert_equal, assert_true, assert_almost_equal, assert_is_instance, assert_is_not\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn import metrics\n",
    "# We do this to ignore several specific warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "631b36a21391f9d153a160244d8eede9",
     "grade": false,
     "grade_id": "cell-d60388a84c8fa3d9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 1\n",
    "\n",
    "In this question, we will be investigating simple text analysis. We will be implementing a simple search algorithm in this question.\n",
    "\n",
    "- Finish the function `get_words` to return a list of strings that are either 5 or 6 characters in length.\n",
    "- The function has one parameter: `text_data` that is a list of strings that will be used in order to find the subset of strings that have either 5 or 6 characters.\n",
    "- For example, if `text_data` = [`hello`, `nice`, `abbrev`, `total`], then the function should return the list: [`hello`, `abbrev`, `total`] as these are the only strings that contain 5 or 6 characters in length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "82350bfdce9dd8cf722356c54359bde5",
     "grade": false,
     "grade_id": "problem1_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_words(text_data):\n",
    "    '''    \n",
    "    Return all 5 or 6 letter words in a list of strings\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text_data: list of strings\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of strings\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    new_data=[]\n",
    "    for word in text_data:\n",
    "        if (len(word) == 5) or (len(word) == 6):\n",
    "            new_data.append(word)\n",
    "            \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "decaa7d25ddcdd7d89932decf618f153",
     "grade": true,
     "grade_id": "problem1_test",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "mvr = nltk.corpus.movie_reviews\n",
    "all_matches = get_words(list(mvr.words()[:1000]))\n",
    "assert_true(type(all_matches) is list)\n",
    "for match in all_matches:\n",
    "    assert_true(len(match) == 5 or len(match) == 6)\n",
    "for match in all_matches:\n",
    "    assert_true(type(match) is str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5096341363b5ee8ddf3a9896a246dffa",
     "grade": false,
     "grade_id": "cell-544e70cc7b248111",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 2\n",
    "\n",
    "In this question, we will be implementing the term frequency algorithm. Use the input list `text_data` and return a dictionary mapping each word to the number of times that word appears in `text_data`.\n",
    "\n",
    "- `text_data` is a list of words of the first 1000 words of the first movie review split by whitespace.\n",
    "- Return a dictionary mapping strings to ints where the strings are the words in `text_data` and the ints are the number of occurences in `text_data`\n",
    "- Also remove the following stop words from the `text_data` before processing the word_counts: [`we`, `for`, `to`, `a`, `(`, `was`, `why`, `ve`, `in`, `is`, `.`, `&`].\n",
    "- Also for the dictionary mapping, please start counting from 1 and not 0 (i.e. on the first occurence of a word, the value for that word in the dictionary should be 1 and not 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "945939c41bc86818991d2b01cf4299f0",
     "grade": false,
     "grade_id": "problem2_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def term_frequency(text_data, stop_words):\n",
    "    '''    \n",
    "    Return a dictionary mapping the words in text_data to the number of occurences in the text_data list\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text_data: list of strings\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A dictionary mapping strings to ints\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    new_data = []\n",
    "    for word in text_data:\n",
    "        if word not in stop_words:\n",
    "            new_data.append(word)\n",
    "            \n",
    "    import collections as cl\n",
    "    wc = cl.Counter(new_data)\n",
    "    \n",
    "    d = {}\n",
    "    for key, value in wc.items():\n",
    "        d[key] = value\n",
    "    \n",
    "    #print(d)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5b48a97b264aa18b7882905f297087fc",
     "grade": true,
     "grade_id": "problem2_test",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "mvr = nltk.corpus.movie_reviews\n",
    "stop_words = ['we', 'for', 'to', 'a', '(', 'was', 'why', 've', 'in', 'is', '.', '&']\n",
    "word_counts = term_frequency(list(mvr.words()[:1000]), stop_words)\n",
    "assert_true(type(word_counts) is dict)\n",
    "for word in stop_words:\n",
    "    assert_true(word not in word_counts.keys())\n",
    "for word in word_counts:\n",
    "    assert_true(type(word) is str)\n",
    "    assert_true(type(word_counts[word]) is int)\n",
    "    assert_true(word_counts[word] > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5dbc81660ac2a313e6763f64b7f9a83a",
     "grade": false,
     "grade_id": "cell-ef5687ed65f8cbfb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Question 3\n",
    "\n",
    "In this question, we will be creating a pipeline that contains a `TFIDFVectorizer` and a `LinearSVC` model for document classification.\n",
    "\n",
    "- Create a pipeline object with a `TFIDFVectorizer` object with the name `tfidf` followed by a `LinearSVC` model with the name `svc`.\n",
    "- Add the value `english` for params `tfidf__stop_words` to the pipeline object.\n",
    "- Fit the model to the `mvr_train` and `y_train` variables.\n",
    "- Return a 2-tuple of the pipeline object followed by the result of the `predict()` function on the `mvr_test` variable.\n",
    "\n",
    "- Order of Pipeline: 1. `TFIDFVectorizer` 2. `LinearSVC`. **Please use the names `tfidf` for the `TFIDFVectorizer` and `svc` for `LinearSVC` or you will NOT pass the tests.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "48dcc481b1b112d5d51947efb1e6edec",
     "grade": false,
     "grade_id": "problem3_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def tfidf_pipeline(mvr_train, y_train, mvr_test):\n",
    "    '''    \n",
    "    Use TFIDFVectorizer and LinearSVC for document classification\n",
    "    using the Pipeline object\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mvr_train: list (independent variable training data)\n",
    "    y_train: np.ndarray (dependent variable training data)\n",
    "    mvr_test: list (independent variable testing data)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 2-tuple of Pipeline object followed by result of the predict() function on the data\n",
    "    attribute of the testing_data\n",
    "    Return type: (pipeline.Pipeline, np.ndarray)\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    pip = Pipeline([('tfidf', TfidfVectorizer()), ('svc', LinearSVC())])\n",
    "\n",
    "    pip.set_params(tfidf__stop_words='english')\n",
    "    \n",
    "    pip.fit(mvr_train, y_train)\n",
    "    \n",
    "    pred = pip.predict(mvr_test)\n",
    "    \n",
    "    return pip, pred\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3bd35aca633761d91384fb2ea3936460",
     "grade": true,
     "grade_id": "problem3_test",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "mvr = nltk.corpus.movie_reviews\n",
    "data_dir = '/home/data_scientist/data/nltk_data/corpora/movie_reviews'\n",
    "mvr = load_files(data_dir, shuffle = False)\n",
    "mvr_train, mvr_test, y_train, y_test = train_test_split(mvr.data, mvr.target, test_size=0.25, random_state=23)\n",
    "pipeline, predicted = tfidf_pipeline(mvr_train, y_train, mvr_test)\n",
    "assert_true(type(pipeline) is Pipeline)\n",
    "assert_true(type(pipeline.get_params()['tfidf']) is TfidfVectorizer)\n",
    "assert_true(type(pipeline.get_params()['svc']) is LinearSVC)\n",
    "assert_true(pipeline.get_params()['tfidf'].get_params()['stop_words'] is 'english')\n",
    "assert_true(type(predicted) is np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3ba9bd69144d9c2c38e5d7ca1adc4fb9",
     "grade": false,
     "grade_id": "cell-8cf501074338b878",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.82      0.82      0.82       259\n",
      "        pos       0.81      0.81      0.81       241\n",
      "\n",
      "avg / total       0.81      0.81      0.81       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the metrics of the document classification model from above\n",
    "mvr = nltk.corpus.movie_reviews\n",
    "data_dir = '/home/data_scientist/data/nltk_data/corpora/movie_reviews'\n",
    "mvr = load_files(data_dir, shuffle = False)\n",
    "mvr_train, mvr_test, y_train, y_test = train_test_split(mvr.data, mvr.target, test_size=0.25, random_state=23)\n",
    "pipeline, predicted = tfidf_pipeline(mvr_train, y_train, mvr_test)\n",
    "print(metrics.classification_report(y_test, predicted, target_names = mvr.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
